seed_everything: 72
model:
  dataset: ${data.dataset}
  arch: conv4
  out_planes: 64
  average_end: false
  gnn_type: gat
  optim: adam
  lr_sch: step
  warmup_start_lr: 1e-3
  warmup_epochs: 250
  sup_finetune_lr: 0.0001563663718906821
  sup_finetune: std_proto # [prototune, std_proto, label_cleansing, sinkhorn]
  sup_finetune_epochs: 15
  eta_min: 5e-5
  lr: 0.0001563663718906821
  inner_lr: 1e-3
  lr_decay_step: 25000
  lr_decay_rate: 0.5
  weight_decay: 6.059722614369727e-06
  img_orig_size: ${data.img_size_orig}
  batch_size: ${data.batch_size}
  task_size: 4
  n_support: ${data.n_support}
  n_query: ${data.n_query}
  use_projector: False
  projector_h_dim: 6400
  projector_out_dim: 1600
  label_cleansing_opts:
    use: False
    n_test_runs: 1000
    n_ways: 5
    n_shots: 5
    n_queries: 15
    unbalanced: False
    reduce: null # ['isomap', 'itsa', 'mds', 'lle', 'se', 'pca', 'none']
    inference_semi: transductive # ['transductive', 'inductive', 'inductive_sk']
    d: 5
    alpha: 0.8
    K: 20 # neighbours used for manifold creation
    T: 3 # power to raise probs matrix before sinkhorn algorithm
    lr: 0.00001 # learning rate of fine-tuning
    denoising_iterations: 1000
    beta_pt: 0.5 # power transform power
    best_samples: 3 # number of best samples per class chosen for pseudolabels
    semi_inference_method: transductive # ['transductive', 'inductive']
    sinkhorn_iter: 1
    use_pt: True # [True, False]
  mpnn_loss_fn: ce
  mpnn_dev: cuda
  mpnn_opts:
    _use: True
    loss_cnn: False
    scaling_ce: 1
    adapt: ot
    temperature: 0.2
    output_train_gnn: plain
    graph_params:
      sim_type: "correlation"
      thresh: "no" #0
      set_negative: "hard"
    gnn_params:
      pretrained_path: "no"
      red: 1
      cat: 0
      every: 0
      gnn:
        num_layers: 1 # for gatv2
        aggregator: "add"
        num_heads: 2
        attention: "dot"
        mlp: 1
        dropout_mlp: 0.1
        norm1: 1
        norm2: 1
        res1: 1
        res2: 1
        dropout_1: 0.1
        dropout_2: 0.1
        mult_attr: 0
      classifier:
        neck: 0
        num_classes: 0
        dropout_p: 0.4
        use_batchnorm: 0
  feature_extractor: null
trainer:
  gpus: -1
  num_sanity_val_steps: 1
  fast_dev_run: false
  max_epochs: 400
  limit_train_batches: 100
  limit_val_batches: 15
  limit_test_batches: 600
  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      name: ${oc.env:SLURM_JOB_ID}
      project: CLR+MAML
      save_dir: wandb_logs
      log_model: True
  callbacks:
    - class_path: pytorch_lightning.callbacks.model_summary.ModelSummary
      init_args:
        max_depth: 3
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        dirpath: ./ckpts/mpnn/${oc.env:SLURM_JOB_ID}
        filename: "{epoch}-{step}-{val/loss:.2f}-{val/accuracy:.3f}-{train/accuracy_epoch:.3f}"
        monitor: "val/accuracy"
        save_last: True
        verbose: True
        every_n_epochs: 1
        mode: "max"
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: "step"
    - class_path: callbacks.ConfidenceIntervalCallback
      init_args:
        log_to_wb: True

data:
  dataset: "miniimagenet"
  datapath: /home/nfs/oshirekar/unsupervised_ml/data/
  full_size_path: /home/nfs/oshirekar/unsupervised_ml/data/miniImageNetFullSize/
  n_support: 1
  n_query: 10
  batch_size: 64
  num_workers: 8
  tfm_method: vicreg
  img_size_orig: [ 84, 84 ]
  img_size_crop: [ 84, 84 ]
  no_aug_support: True