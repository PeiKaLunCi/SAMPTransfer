job_name: local_test
seed_everything: 72
slurm:
  nodes: 1
  timeout: 8
  mem_gb: 10
  partition: general
  constraint: ""
  comment: ""
  slurm_additional_parameters:
    qos: medium
    gres: gpu:a40:1
    signal: SIGUSR1@90
model:
  optim: "radam"
  lr_sch: "step"
  warmup_start_lr: 1e-3
  warmup_epochs: 250
  eta_min: 1e-5
  lr: 1e-3
  lr_decay_step: 25000 # applies only for Step LR
  lr_decay_rate: 0.5 # applies only for Step LR
  weight_decay: 0.0001
  alpha_cosine: False # Doesn't really matter here
  bow_clr: False
  clr_loss: False
  clr_on_bow: True
  vicreg_opts:
    use_vicreg: False
  graph_conv_opts:
    use_graph_conv: False
    k: 5
    aggregation: mean
    mlp: False
    task_adapt: False
    m_scale:
      use_m_scale: False
      m_scale_projector_dim: 512
      attn_pooling: False
      attn_inner_dim: 64
      heads: 1
      graph_conv: False
      resizing: interpolate
  mpnn_loss_fn: ce
  mpnn_opts:
    _use: False
    loss_cnn: False
    scaling_ce: 1
    task_adapt: False
    temperature: 0.2
    output_train_gnn: plain
    graph_params:
      sim_type: "correlation"
      thresh: "no" #0
      set_negative: "hard"
    gnn_params:
      pretrained_path: "no"
      red: 1
      cat: 0
      every: 0
      gnn:
        num_layers: 1
        aggregator: "add"
        num_heads: 2
        attention: "dot"
        mlp: 1
        dropout_mlp: 0.1
        norm1: 1
        norm2: 1
        res1: 1
        res2: 1
        dropout_1: 0.1
        dropout_2: 0.1
        mult_attr: 0
      classifier:
        neck: 1
        num_classes: 0
        dropout_p: 0.4
        use_batchnorm: 0
  bow_levels: [ "block4" ]
  bow_extractor_opts:
    inv_delta: 10
    num_words: 2048
  bow_predictor_opts:
    kappa: 5
  alpha: 0.99
  feature_extractor:
    class_path: bow.feature_extractor.CNN_4Layer
    init_args:
      in_channels: 3
      hidden_size: 64
      out_channels: 64
      last_maxpool: True
      global_pooling: False
trainer:
  gpus: -1
  num_sanity_val_steps: 1
  fast_dev_run: 0
  max_epochs: 1500
  limit_train_batches: 100
  limit_val_batches: 15
  callbacks:
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        dirpath: "./ckpts/"
        monitor: "val_accuracy"
        save_top_k: 10
        every_n_epochs: 1
        mode: "max"
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        patience: 200
        monitor: "val_accuracy"
        mode: "max"
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: "step"

data:
  dataset: "miniimagenet"
  datapath: /home/ojass/projects/unsupervised-meta-learning/data/untarred/miniimagenet
  n_support: 1
  n_query: 3
  batch_size: 64
  num_workers: 0
  img_size_orig: [ 84, 84 ]
  img_size_crop: [ 84, 84 ]
  no_aug_support: True