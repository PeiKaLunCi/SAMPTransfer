job_name: local_test
seed_everything: 72
model:
  lr: 0.0005
  min_lr: 1e-6
  warmup_epochs: 30
  lr_sch: None
  lr_decay_step: 25000
  lr_decay_rate: 0.5
  sup_finetune: True
  sup_finetune_lr: 1e-4
  sup_finetune_epochs: 15
  ft_freeze_backbone: True
  finetune_batch_norm: False
  finetune_task_adapt: True
  use_bn_in_head: False
  norm_last_layer: False
  drop_path_rate: 0.1
  img_orig_size: ${data.img_size_orig}
  eval_ways: 5
  loss_fn:
    class_path: losses.HLoss
    init_args:
      temperature_s: 0.1
      temperature_t: 0.05
  center_momentum: .9
  param_momentum: .995
  dim: 1024 # for output, configurable for ViT projector, set head=True if needed
  encoder:
    model: vit_tiny
    dev: cuda
    head: True
  gnn_opts:
    use: True
    gat_version: v1
    loss_cnn: True
    scaling_ce: 1
    task_adapt: False
    temperature: 0.2
    output_train_gnn: plain
    graph_params:
      sim_type: "correlation"
      thresh: "no" #0
      set_negative: "hard"
    gnn_params:
      pretrained_path: "no"
      red: 1
      cat: 0
      every: 0
      gnn:
        num_layers: 1
        aggregator: "add"
        num_heads: 8
        attention: "dot"
        mlp: 1
        dropout_mlp: 0.1
        norm1: 1
        norm2: 1
        res1: 1
        res2: 1
        dropout_1: 0.1
        dropout_2: 0.1
        mult_attr: 0
      classifier:
        neck: 1
        num_classes: 0
        dropout_p: 0.4
        use_batchnorm: 0

trainer:
  gpus: -1
  #  gradient_clip_val: 0.5
  num_sanity_val_steps: 1
  fast_dev_run: 0
  max_epochs: 100
#  limit_train_batches: 100
  limit_val_batches: 15
  #  logger:
  #    class_path: pytorch_lightning.loggers.CometLogger
  #    init_args:
  #      save_dir: "./comet"
  #      api_key: ${oc.env:COMET_API_KEY}
  #      rest_api_key: ${oc.env:COMET_API_KEY}
  #      project_name: testing
  #      experiment_name: ${job_name}
  #    class_path: pytorch_lightning.loggers.WandbLogger
  #    init_args:
  #      project: testing
  #      save_dir: wandb_logs
  #      log_model: True
  callbacks:
    - class_path: pytorch_lightning.callbacks.model_summary.ModelSummary
      init_args:
        max_depth: 3
    #    - class_path: callbacks.EmbeddingLogger
    #      init_args:
    #        every_n_steps: 1
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        dirpath: "./ckpts/"
        monitor: "val_accuracy"
        save_top_k: 10
        every_n_epochs: 1
        mode: "max"

    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        patience: 200
        monitor: "val_accuracy"
        mode: "max"
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: "step"


data:
  dataset: "miniimagenet"
  #  datapath: ../data/
  datapath: /home/ojass/projects/unsupervised-meta-learning/data/untarred/
  full_size_path: /home/ojass/projects/data/processed_images/
  #  datapath: /home/nfs/oshirekar/unsupervised_ml/data/miniimagenet
  n_support: 1
  n_query: 1
  batch_size: 16
  num_workers: 0
  tfm_method: vicreg
  img_size_orig: [ 224, 224 ]
  img_size_crop: [ 224, 224 ]
  no_aug_support: True

#data:
#  dataset: "miniimagenet"
#  #  datapath: ../data/
#  datapath: /home/ojass/projects/unsupervised-meta-learning/data/untarred/
#  full_size_path: /home/ojass/projects/data/processed_images/
#  #  datapath: /home/nfs/oshirekar/unsupervised_ml/data/miniimagenet
#  n_support: 1
#  n_query: 1
#  batch_size: 64
#  num_workers: 0
#  tfm_method: vicreg
#  img_size_orig: [ 84, 84 ]
#  img_size_crop: [ 84, 84 ]
#  no_aug_support: True